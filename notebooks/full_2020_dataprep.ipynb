{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import zebra\n",
    "import re\n",
    "solver_data = pd.read_excel(\"2020_Partner_Solver_original.xlsx\", sheet_name='Solver Data')\n",
    "partner_data =  pd.read_excel(\"2020_Partner_Solver_original.xlsx\", sheet_name='Partner Data')\n",
    "solver_data = solver_data.rename(columns={'Solution Name': 'Org'})\n",
    "partner_data = partner_data.rename(columns={'Organization Name': 'Org',\n",
    "                                            'Challenge':'Challenge Preference',\n",
    "                                            'Stage': 'Solution Preference: Organization Stage',\n",
    "                                            'Expertise': 'Partnership Preference: Non-Financial',\n",
    "                                           'Geography': 'Geo Interests'})\n",
    "\n",
    "partner_data = partner_data.replace(np.nan, \"Noval\")\n",
    "solver_data  = solver_data.replace(np.nan, \"Noval\")\n",
    "solver_data_copy = solver_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_collect(df_cols, delimiter=','):\n",
    "    \"\"\"\n",
    "        Split each value in a cell based on a delimiter \n",
    "        and return a list of unique options \n",
    "        \n",
    "    \"\"\"\n",
    "    opts = df_cols.apply(lambda x :  x.split(delimiter)   ).to_list()\n",
    "    flatten_opts = [x.strip() for y in opts for x in y ]\n",
    "    opts = pd.DataFrame(data=flatten_opts, columns=['options'])\n",
    "    opts = opts['options'].value_counts().index.to_list()\n",
    "    return opts\n",
    "\n",
    "\n",
    "def expand_col(df_col, delimiter=',',col_name='new_col'): \n",
    "    \"\"\"\n",
    "    Take in a pandas series whose elements are\n",
    "    a string. Split each cell of the series with\n",
    "    a delimiter which is used togenerate an N column dataframe. \n",
    "    N is the longest list amongst the cells of df_col after\n",
    "    they have been split\n",
    "    \n",
    "    \"\"\"\n",
    "#     df_col = df_col.apply(lambda x : x.str.split(delimiter)).to_list()\n",
    "    df_col = df_col.str.split(delimiter).to_list()\n",
    "    new_df = pd.DataFrame(data=df_col)\n",
    "    ncols = len(new_df.columns)\n",
    "    new_names = []\n",
    "    for x in range(1, ncols+1): \n",
    "        new_name =\"\".join((col_name,'_', str(x)))\n",
    "        new_df = new_df.rename(columns={x-1:new_name})\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def match_single_to_multi(single_df, multi_df, single_match_on='None'): \n",
    "    \"\"\"\n",
    "    Generate a pivot table between a df which has a single of choices \n",
    "    and a df with multiple columns of choices\n",
    "    \n",
    "    \"\"\"\n",
    "    melted_df = pd.melt(multi_df,id_vars='Org')\n",
    "    melted_df = melted_df.drop(columns='variable')\n",
    "    melted_df = melted_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    single_df = single_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    matched_df = pd.merge(melted_df, single_df, how='outer', left_on='value', right_on=single_match_on)\n",
    "    matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "    matched_df['value'] = matched_df['value'].apply(lambda x : 0 if x == None else 1)\n",
    "    pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value', dropna=False,  aggfunc=np.sum)\n",
    "\n",
    "    return pivot_table\n",
    "\n",
    "\n",
    "def match_multi(df1, df2):\n",
    "    \"\"\"\n",
    "    Match a feature with multiple options to another option with multiple options\n",
    "    \"\"\"\n",
    "    \n",
    "    melted_df1 = pd.melt(df1,id_vars='Org').fillna('Noval')\n",
    "    melted_df2 = pd.melt(df2, id_vars='Org').fillna('Noval')\n",
    "    melted_df1 = melted_df1.drop(columns='variable')\n",
    "    melted_df2 = melted_df2.drop(columns='variable')\n",
    "    melted_df1 = melted_df1.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    melted_df2 = melted_df2.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    matched_df = pd.merge(melted_df1, melted_df2, how='outer', left_on='value', right_on='value')\n",
    "    matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "    matched_df['value'] = matched_df['value'].apply(lambda x : 0 if  x == 'Noval' else 1)\n",
    "    pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value',aggfunc=np.sum)\n",
    "    return pivot_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge column cleaning and matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_challenge  = partner_data['Challenge Preference']\n",
    "partner_data['Challenge Preference'] = partner_data['Challenge Preference'].apply(lambda x: x.strip().replace(';',',') if ';' in x else x.strip() )\n",
    "partner_challenge_cols = expand_col(partner_data['Challenge Preference'], col_name ='Challenge')\n",
    "partner_challenge_opts = split_collect(partner_data['Challenge Preference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_challenge_opts = split_collect(solver_data['Challenge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_challenge_opts).issubset(set(partner_challenge_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that all options in solvers are a subset of patners so no work required in correction! Next up is getting the matching sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add challenge columns to partner data sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated = partner_data.copy()\n",
    "partner_data_updated = partner_data_updated.drop(columns='Challenge Preference')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_challenge_cols], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['North America',\n",
       " 'East Asia and Pacific',\n",
       " 'Sub-Saharan Africa',\n",
       " 'Europe and Central Asia',\n",
       " 'Latin America and the Caribbean',\n",
       " 'Middle East and North Africa',\n",
       " 'South Asia',\n",
       " 'Oceania',\n",
       " 'Noval']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_data_updated['Geo Interest'] = partner_data_updated['Geo Interest'].apply(lambda x: x.strip().replace(';',',') if ';' in x else x.strip() )\n",
    "partner_geo_opts = split_collect(partner_data_updated['Geo Interest'])\n",
    "partner_geo_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'North America',\n",
       " 'Sub-Saharan Africa',\n",
       " 'South Asia',\n",
       " 'Middle East and North Africa',\n",
       " 'Latin America and the Caribbean',\n",
       " 'Europe and Central Asia',\n",
       " 'East Asia and Pacific']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_geo_opts = solver_data[['Geo 1', 'Geo 2', 'Geo 3']].apply(lambda x : \",\".join(x)   ,axis=1)\n",
    "solver_geo_opts = split_collect(solver_geo_opts)\n",
    "solver_geo_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_geo_opts).issubset(set(partner_geo_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add geo columns to partner datasheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_geo_cols = partner_data_updated['Geo Interest']\n",
    "\n",
    "partner_geo_cols = expand_col(partner_geo_cols, col_name='geo')\n",
    "\n",
    "# remove partner geo column and add individual geo columns\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_geo_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Geo Interest'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (e.g. sourcing talent, board development, etc.)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Other (explain below)',\n",
       " 'Legal or Regulatory Matters']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Partnership preferences non financal from partner data\n",
    "\n",
    "pref_name = 'Partnership Preference'\n",
    "prefs_columns = [x  for x in partner_data_updated.columns if pref_name in x]\n",
    "partner_prefs_opts = partner_data_updated[prefs_columns]\n",
    "partner_prefs_opts = split_collect(partner_prefs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "partner_prefs_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Human Capital (e.g. sourcing talent, board development, etc.)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Legal or Regulatory Matters',\n",
       " 'Other',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (i.e. sourcing talent, board development, etc.)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needs_name = 'Key Need'\n",
    "needs_columns = [x  for x in solver_data.columns if needs_name in x]\n",
    "solver_needs_opts = solver_data[needs_columns]\n",
    "solver_needs_opts = split_collect(solver_needs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "solver_needs_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Human Capital (i.e. sourcing talent, board development, etc.)', 'Other'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all the solver need options are in partner preferences\n",
    "set(solver_needs_opts).difference(set(partner_prefs_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other (explain below)'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the opposite of the above\n",
    "set(partner_prefs_opts).difference(set(solver_needs_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Human Captial in partner data\n",
    "wrong_str1 = 'Human Capital (e.g. sourcing talent, board development, etc.)'\n",
    "wrong_str2 = 'Other (explain below)'\n",
    "correct_str1 = 'Other'\n",
    "correct_str2 = 'Human Capital (i.e. sourcing talent, board development, etc.)'\n",
    "for pref in prefs_columns:\n",
    "    partner_data_updated[pref] = partner_data_updated[pref].apply(lambda x: x.replace(wrong_str1, correct_str1) if x == wrong_str1 else x )\n",
    "    partner_data_updated[pref] = partner_data_updated[pref].apply(lambda x: x.replace(wrong_str2, correct_str2) if x == wrong_str2 else x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Capital in solver data\n",
    "wrong_str1 = 'Human Capital (e.g. sourcing talent, board development, etc.)'\n",
    "correct_str2 = 'Human Capital (i.e. sourcing talent, board development, etc.)'\n",
    "solver_data_updated = solver_data.copy()\n",
    "for pref in needs_columns:\n",
    "    solver_data_updated[pref] = solver_data_updated[pref].apply(lambda x: x.replace(wrong_str1, correct_str1) if x == wrong_str1 else x )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noval',\n",
       " 'Other',\n",
       " 'Public Relations (e.g. branding/marketing strategy, social and global media)',\n",
       " 'Financial (e.g. improving accounting practices, pitching to investors)',\n",
       " 'Business model (e.g. product-market fit, strategy & development)',\n",
       " 'Product / Service Distribution (e.g. expanding client base)',\n",
       " 'Technology (e.g. software or hardware, web development/design, data analysis, etc.)',\n",
       " 'Legal or Regulatory Matters',\n",
       " 'Monitoring & Evaluation (e.g. collecting/using data, measuring impact)',\n",
       " 'Human Capital (i.e. sourcing talent, board development, etc.)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the partnership options after correcting for human capital\n",
    "needs_columns = [x  for x in solver_data_updated.columns if needs_name in x]\n",
    "solver_needs_opts = solver_data_updated[needs_columns]\n",
    "solver_needs_opts = split_collect(solver_needs_opts.apply(lambda x : \";\".join(x)   ,axis=1), delimiter=';')\n",
    "solver_needs_opts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated['Solution Preference: Organization Stage'] = partner_data_updated['Solution Preference: Organization Stage'].apply(lambda x : x.replace(';',',' if ';' in x else x))\n",
    "partner_stage = partner_data_updated['Solution Preference: Organization Stage']\n",
    "partner_stage_opts = split_collect(partner_stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_stage_opts = split_collect(solver_data_updated['Stage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(solver_stage_opts).difference(set(partner_stage_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No difference! means all the options are the same! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add seprated stage columns to partner data sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_stage_cols = expand_col(partner_stage, col_name='Stage')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_stage_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Solution Preference: Organization Stage'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imaging and Sensor Technology', 'Virtual Reality / Augmented Reality'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_tech_opts = split_collect(partner_data_updated['Technology Expertise'])\n",
    "tech_name = 'Tech'\n",
    "tech_cols = [x for x in solver_data_updated.columns if  tech_name in x]\n",
    "tech_cols.append('Org')\n",
    "solver_tech_cols = solver_data_updated[tech_cols]\n",
    "solver_tech_opts = split_collect(solver_tech_cols.apply(lambda x : \",\".join(x), axis=1))\n",
    "set(partner_tech_opts).difference(solver_tech_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_tech_cols = expand_col(partner_data_updated['Technology Expertise'], col_name='tech')\n",
    "partner_data_updated = pd.concat([partner_data_updated, partner_tech_cols], axis=1)\n",
    "partner_data_updated = partner_data_updated.drop(columns=['Technology Expertise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All matching sheets calculated here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Challenge Matching sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Organization ID', 'Org', 'First Name', 'Last Name',\n",
       "       'Type', 'Funding Preference 1', 'Funding Preference 2',\n",
       "       'Funding Preference 3', 'Funding Preference 4',\n",
       "       'Partnership Preference: Non-Financial 1',\n",
       "       'Partnership Preference: Non-Financial 2',\n",
       "       'Partnership Preference: Non-Financial 3',\n",
       "       'Partnership Preference: Non-Financial 4',\n",
       "       'Partnership Preference: Non-Financial 5',\n",
       "       'Partnership Preference: Non-Financial 6',\n",
       "       'Partnership Preference: Non-Financial 7', 'Challenge_1', 'Challenge_2',\n",
       "       'Challenge_3', 'Challenge_4', 'Challenge_5', 'Challenge_6',\n",
       "       'Challenge_7', 'Challenge_8', 'Challenge_9', 'Challenge_10',\n",
       "       'Challenge_11', 'Challenge_12', 'Challenge_13', 'Challenge_14', 'geo_1',\n",
       "       'geo_2', 'geo_3', 'geo_4', 'geo_5', 'geo_6', 'geo_7', 'geo_8',\n",
       "       'Stage_1', 'Stage_2', 'Stage_3', 'Stage_4', 'Stage_5', 'tech_1',\n",
       "       'tech_2', 'tech_3', 'tech_4', 'tech_5', 'tech_6', 'tech_7', 'tech_8',\n",
       "       'tech_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_data_updated = partner_data_updated.replace('None', 'Noval' ,regex=True)\n",
    "solver_data_updated = solver_data_updated.replace('None', 'Noval', regex=True)\n",
    "partner_data_updated = partner_data_updated.replace(np.nan, \"Noval\")\n",
    "solver_data_updated  = solver_data_updated.replace(np.nan, \"Noval\")\n",
    "partner_data_updated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chname = 'Challenge'\n",
    "challenge_cols = [x for x in partner_data_updated.columns if chname in x ]\n",
    "partner_challenge_cols = partner_data_updated[challenge_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "solver_challenge_cols = solver_data_updated[['Org', 'Challenge']]\n",
    "partner_challenge_cols['Org'] = partner_data_updated['Org']\n",
    "challenge_match = match_single_to_multi(solver_challenge_cols, partner_challenge_cols, single_match_on='Challenge')\n",
    "\n",
    "if 'Noval' in challenge_match.columns: \n",
    "    challenge_match = challenge_match.drop(columns=['Noval'])\n",
    "challenge_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening up single to multi function \n",
    "\n",
    "# single_df = solver_challenge_cols\n",
    "# multi_df = partner_challenge_cols\n",
    "# single_match_on = 'Challenge'\n",
    "\n",
    "# melted_df = pd.melt(multi_df,id_vars='Org')\n",
    "# melted_df = melted_df.drop(columns='variable')\n",
    "# melted_df = melted_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# single_df = single_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# matched_df = pd.merge(melted_df, single_df, how='outer', left_on='value', right_on=single_match_on)\n",
    "# matched_df = matched_df.replace(np.nan, 'Noval')\n",
    "# matched_df['value'] = matched_df['value'].apply(lambda x : 0 if x == None else 1)\n",
    "# pivot_table = pd.pivot_table(matched_df, index='Org_x', columns=['Org_y'], values='value', dropna=False,  aggfunc=np.sum)\n",
    "# pivot_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trouble shooting no match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unshared_challenges_partners = set(partner_challenge_cols['Org'].to_list()).difference(set(pivot_table.index.to_list()))\n",
    "# challenges_missing = set(partner_challenge_opts).difference(set(solver_challenge_opts))\n",
    "# missing_indx = partner_challenge_cols[partner_challenge_cols.isin(challenges_missing)].any(1).to_numpy().nonzero()\n",
    "# possible_missing = partner_challenge_cols['Org'].loc[missing_indx].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basically means that there are only 35 rows have matches, otherwise no matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_cols = [x for x in partner_data_updated.columns if 'geo' in x]\n",
    "geo_cols.append('Org')\n",
    "partner_geo_cols = partner_data_updated[geo_cols]\n",
    "\n",
    "solver_geo_cols = solver_data_updated[['Org', 'Geo 1', 'Geo 2', 'Geo 3']]\n",
    "geo_match = match_multi(partner_geo_cols,solver_geo_cols)\n",
    "if 'Noval' in geo_match.columns: \n",
    "    geo_match = geo_match.drop(columns=['Noval'])\n",
    "geo_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needs Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needs_name ='Key Need'\n",
    "pref_name = 'Partnership Preference'\n",
    "prefs_columns = [x  for x in partner_data_updated.columns if pref_name in x]\n",
    "needs_columns = [x  for x in solver_data_updated.columns if needs_name in x]\n",
    "prefs_columns.append('Org')\n",
    "needs_columns.append('Org')\n",
    "partner_prefs_cols = partner_data_updated[prefs_columns]\n",
    "solver_needs_cols = solver_data_updated[needs_columns]\n",
    "needs_match = match_multi(partner_prefs_cols, solver_needs_cols)\n",
    "if 'Noval' in needs_match.columns: \n",
    "    needs_match = needs_match.drop(columns=['Noval'])\n",
    "needs_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Matching sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_name = 'Stage'\n",
    "stage_columns = [x  for x in partner_data_updated.columns if stage_name in x]\n",
    "stage_columns.append('Org')\n",
    "partner_stage_cols = partner_data_updated[stage_columns]\n",
    "solver_stage_cols = solver_data_updated[['Stage', 'Org']]\n",
    "stage_match = match_single_to_multi(solver_stage_cols, partner_stage_cols, single_match_on='Stage')\n",
    "\n",
    "if 'Noval' in stage_match.columns: \n",
    "    stage_match = stage_match.drop(columns=['Noval'])\n",
    "stage_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stage_match.columns.to_list()).difference(set(needs_match.columns.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Matching Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_name = 'tech'\n",
    "tech_cols = [x for x in partner_data_updated.columns if  tech_name in x]\n",
    "tech_cols.append('Org')\n",
    "partner_tech_cols = partner_data_updated[tech_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(78, 43)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partner_tech_cols['Org'] = partner_data_updated['Org']\n",
    "tech_match = match_multi(partner_tech_cols, solver_tech_cols)\n",
    "if 'Noval' in tech_match.columns:\n",
    "    tech_match = tech_match.drop(columns=['Noval'])\n",
    "if 'Noval' in tech_match.index:\n",
    "    tech_match = tech_match.drop(index='Noval', axis=0) \n",
    "tech_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing all sheets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech_matched = tech_matched.fillna(0)\n",
    "needs_match = needs_match.fillna(0)\n",
    "geo_match = geo_match.fillna(0)\n",
    "stage_match= stage_match.fillna(0)\n",
    "challenge_match = challenge_match.fillna(0)\n",
    "\n",
    "partner_solver_weights = pd.read_excel('input_data/2020_input_data.xlsx', sheet_name= 'Partner Solver Weights')\n",
    "geo_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'geo_weights']], columns='Org_x', index='Org_y' )\n",
    "needs_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'needs_weights']], columns='Org_x', index='Org_y' )\n",
    "challenge_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'challenge_weights']], columns='Org_x', index='Org_y' )\n",
    "stage_weights_pivot = pd.pivot(partner_solver_weights[['Org_y', 'Org_x', 'stage_weights']], columns='Org_x', index='Org_y' )\n",
    "\n",
    "challenge_term = 10*pd.DataFrame(challenge_weights_pivot.values*challenge_match.astype(float).values, columns=challenge_weights_pivot.columns, index=challenge_weights_pivot.index)['challenge_weights']\n",
    "stage_term = pd.DataFrame(stage_weights_pivot.values*stage_match.astype(float).values, columns=stage_weights_pivot.columns, index=stage_weights_pivot.index)\n",
    "geo_term = pd.DataFrame(geo_weights_pivot.values*geo_match.astype(float).values, columns=geo_weights_pivot.columns, index=geo_weights_pivot.index)['geo_weights']\n",
    "geo_stage_term = 100*pd.DataFrame(geo_term.values*stage_term.values, columns=stage_term.columns, index=stage_term.index)['stage_weights']\n",
    "needs_term =  pd.DataFrame(needs_weights_pivot.values*needs_match.astype(float).values, columns=needs_weights_pivot.columns, index=needs_weights_pivot.index)['needs_weights']\n",
    "\n",
    "total_score = challenge_term  + geo_stage_term + needs_term\n",
    "# partner_solver_weights['Org_x'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_data_updated = partner_data_updated.replace('None', 'Noval' ,regex=True)\n",
    "solver_data_updated = solver_data_updated.replace('None', 'Noval', regex=True)\n",
    "partner_data_updated = partner_data_updated.replace(np.nan, \"Noval\")\n",
    "solver_data_updated  = solver_data_updated.replace(np.nan, \"Noval\")\n",
    "\n",
    "file_name = '2020_data.xlsx'\n",
    "with pd.ExcelWriter(file_name) as writer: \n",
    "    partner_data_updated.to_excel(writer, sheet_name='Partner Data', index=False)\n",
    "    solver_data_updated.to_excel(writer, sheet_name='Solver Team Data', index= False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sort values for the output graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_df_total_score = pd.read_excel(\"input_data/total_score_from_upload.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Org_y</th>\n",
       "      <th>EA Ecoversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Comcast NBCUniversal</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Someone Else's Child Foundation</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BMW Foundation Herbert Quandt</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Llamasoft</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Merian Ventures</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Morgridge Family Foundation</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Global Fund to fight Aids, Tuberculosis and Ma...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>KSF Impact</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Leap Ventures</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Queen Rania Foundation for Education and Devel...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Org_y  EA Ecoversity\n",
       "16                               Comcast NBCUniversal           13.0\n",
       "58                    Someone Else's Child Foundation           12.0\n",
       "6                       BMW Foundation Herbert Quandt           11.0\n",
       "40                                          Llamasoft            6.0\n",
       "44                                    Merian Ventures            6.0\n",
       "..                                                ...            ...\n",
       "46                        Morgridge Family Foundation            1.0\n",
       "29  Global Fund to fight Aids, Tuberculosis and Ma...            0.0\n",
       "35                                         KSF Impact            0.0\n",
       "38                                      Leap Ventures            0.0\n",
       "54  Queen Rania Foundation for Education and Devel...            0.0\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = 'EA Ecoversity'\n",
    "solver_scores = uploaded_df_total_score[['Org_y', value]]\n",
    "uploaded_df_total_score.sort_values(value,  ascending=False)[:5]\n",
    "solver_scores.sort_values(by=[ value], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Org_y</th>\n",
       "      <th>AHSA Platform</th>\n",
       "      <th>Amplify Her Voice</th>\n",
       "      <th>Asia Initiatives Learning Cascades</th>\n",
       "      <th>Bambara Milk</th>\n",
       "      <th>Beewise</th>\n",
       "      <th>Bioforge Neonatal Incubator</th>\n",
       "      <th>Biometricsfor vaccine delivery</th>\n",
       "      <th>D2</th>\n",
       "      <th>Democratizing Ultrasound Africa</th>\n",
       "      <th>...</th>\n",
       "      <th>Someone Somewhere</th>\n",
       "      <th>Symbrosia</th>\n",
       "      <th>TamoJunto.org.br</th>\n",
       "      <th>Thaki</th>\n",
       "      <th>The Last Mile</th>\n",
       "      <th>Ubenwa</th>\n",
       "      <th>Universally Friendly Obturator</th>\n",
       "      <th>Whole Surplus</th>\n",
       "      <th>Yiya AirScience</th>\n",
       "      <th>eggXYt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Comcast NBCUniversal</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Someone Else's Child Foundation</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BMW Foundation Herbert Quandt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Llamasoft</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Merian Ventures</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Org_y  AHSA Platform  Amplify Her Voice  \\\n",
       "16             Comcast NBCUniversal              4                  3   \n",
       "58  Someone Else's Child Foundation              6                 14   \n",
       "6     BMW Foundation Herbert Quandt              2                  2   \n",
       "40                        Llamasoft              4                 12   \n",
       "44                  Merian Ventures              6                  2   \n",
       "\n",
       "    Asia Initiatives Learning Cascades  Bambara Milk  Beewise  \\\n",
       "16                                   6             1        2   \n",
       "58                                  16             2        2   \n",
       "6                                    4             1        2   \n",
       "40                                  17            12       15   \n",
       "44                                   6            11       16   \n",
       "\n",
       "    Bioforge Neonatal Incubator  Biometricsfor vaccine delivery  D2  \\\n",
       "16                            2                               3  12   \n",
       "58                            2                               4  12   \n",
       "6                             0                               3  10   \n",
       "40                           11                               2   3   \n",
       "44                            1                               2  12   \n",
       "\n",
       "    Democratizing Ultrasound Africa  ...  Someone Somewhere  Symbrosia  \\\n",
       "16                                2  ...                 13          4   \n",
       "58                                3  ...                 14          4   \n",
       "6                                 3  ...                 14          1   \n",
       "40                               13  ...                  5         12   \n",
       "44                                2  ...                 13         13   \n",
       "\n",
       "    TamoJunto.org.br  Thaki  The Last Mile  Ubenwa  \\\n",
       "16                13      5             14       2   \n",
       "58                14     14             13       2   \n",
       "6                 13      4             13       1   \n",
       "40                 3     16              4      13   \n",
       "44                12      4             14       3   \n",
       "\n",
       "    Universally Friendly Obturator  Whole Surplus  Yiya AirScience  eggXYt  \n",
       "16                               6              2                5       2  \n",
       "58                               6              2               16       3  \n",
       "6                                2              2                2       1  \n",
       "40                              13             14               14      12  \n",
       "44                               3             16                5      11  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_df_total_score.sort_values(value,  ascending=False)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49    3.0\n",
       "Name: EA Ecoversity, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "solver_scores[solver_scores['Org_y'] == 'Nuvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16    12\n",
       "Name: D2, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_df_total_score.sort_values(value,  ascending=False)[:1]['D2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
